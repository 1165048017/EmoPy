
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>FERNeuralNets &#8212; EmoPy 1.0 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ImageProcessor" href="imageprocessor.html" />
    <link rel="prev" title="FERModel" href="fermodel.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="imageprocessor.html" title="ImageProcessor"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="fermodel.html" title="FERModel"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">EmoPy 1.0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-neuralnets">
<span id="ferneuralnets"></span><h1>FERNeuralNets<a class="headerlink" href="#module-neuralnets" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="neuralnets.ConvolutionalLstmNN">
<em class="property">class </em><code class="descclassname">neuralnets.</code><code class="descname">ConvolutionalLstmNN</code><span class="sig-paren">(</span><em>image_size</em>, <em>channels</em>, <em>target_labels</em>, <em>time_delay=2</em>, <em>filters=10</em>, <em>kernel_size=(4</em>, <em>4)</em>, <em>activation='sigmoid'</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#ConvolutionalLstmNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.ConvolutionalLstmNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolutional Long Short Term Memory Neural Network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image_size</strong> – dimensions of input images</li>
<li><strong>channels</strong> – number of image channels</li>
<li><strong>target_labels</strong> – list of target emotion labels</li>
<li><strong>time_delay</strong> – number time steps for lookback</li>
<li><strong>filters</strong> – number of filters/nodes per layer in CNN</li>
<li><strong>kernel_size</strong> – size of sliding window for each layer of CNN</li>
<li><strong>activation</strong> – name of activation function for CNN</li>
<li><strong>verbose</strong> – if true, will print out extra process information</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">target_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
<span class="n">csv_file_path</span> <span class="o">=</span> <span class="s2">&quot;&lt;local csv file path&gt;&quot;</span>

<span class="n">imageProcessor</span> <span class="o">=</span> <span class="n">ImageProcessor</span><span class="p">(</span><span class="n">from_csv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">target_labels</span><span class="o">=</span><span class="n">target_labels</span><span class="p">,</span> <span class="n">datapath</span><span class="o">=</span><span class="n">csv_file_path</span><span class="p">,</span> <span class="n">target_dimensions</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span> <span class="n">raw_dimensions</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">),</span> <span class="n">csv_label_col</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">csv_image_col</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imageProcessor</span><span class="o">.</span><span class="n">get_training_data</span><span class="p">()</span>

<span class="n">featureExtractor</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">return_2d_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">featureExtractor</span><span class="o">.</span><span class="n">add_feature</span><span class="p">(</span><span class="s1">&#39;hog&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;orientations&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;pixels_per_cell&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s1">&#39;cells_per_block&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)})</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">featureExtractor</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">ConvolutionalLstmNN</span><span class="p">(</span><span class="n">target_dimensions</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span> <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">target_labels</span><span class="o">=</span><span class="n">target_labels</span><span class="p">,</span> <span class="n">time_delay</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="neuralnets.ConvolutionalLstmNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>features</em>, <em>labels</em>, <em>validation_split</em>, <em>batch_size=10</em>, <em>epochs=50</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#ConvolutionalLstmNN.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.ConvolutionalLstmNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the neural net on the data provided.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> – Numpy array of training data.</li>
<li><strong>labels</strong> – Numpy array of target (label) data.</li>
<li><strong>validation_split</strong> – Float between 0 and 1. Percentage of training data to use for validation</li>
<li><strong>batch_size</strong> – </li>
<li><strong>epochs</strong> – number of times to train over input dataset.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="neuralnets.ConvolutionalLstmNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#ConvolutionalLstmNN.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.ConvolutionalLstmNN.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuralnets.TimeDelayNN">
<em class="property">class </em><code class="descclassname">neuralnets.</code><code class="descname">TimeDelayNN</code><span class="sig-paren">(</span><em>feature_vector_length</em>, <em>time_delay=3</em>, <em>num_output_values=4</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TimeDelayNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TimeDelayNN" title="Permalink to this definition">¶</a></dt>
<dd><p>This model is broken down into two steps: regression and CNN variant.
The regression step is trained on the supplied image dataset, and its output is used to train the CNN. The output from the regression step is preprocessed to create new “time-delayed” datapoints. In other words, the output becomes 3-dimensional (1, regression_output_dim, number_of_previous_time_steps_considered +1)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>feature_vector_length</strong> – length of input feature vectors used to train regression step</li>
<li><strong>time_delay</strong> – number of previous datapoints to consider for each new datapoint in CNN step</li>
<li><strong>num_output_values</strong> – number of classification labels</li>
<li><strong>verbose</strong> – if true, will print out extra process information</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">target_dimensions</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">target_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>

<span class="n">root_directory</span> <span class="o">=</span> <span class="s1">&#39;&lt;local training image directory&gt;&#39;</span>
<span class="n">imageProcessor</span> <span class="o">=</span> <span class="n">ImageProcessor</span><span class="p">(</span><span class="n">from_csv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">target_labels</span><span class="o">=</span><span class="n">target_labels</span><span class="p">,</span> <span class="n">datapath</span><span class="o">=</span><span class="n">root_directory</span><span class="p">,</span> <span class="n">target_dimensions</span><span class="o">=</span><span class="n">target_dimensions</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imageProcessor</span><span class="o">.</span><span class="n">get_training_data</span><span class="p">()</span>

<span class="n">featureExtractor</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">return_2d_array</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">featureExtractor</span><span class="o">.</span><span class="n">add_feature</span><span class="p">(</span><span class="s1">&#39;hog&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;orientations&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;pixels_per_cell&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s1">&#39;cells_per_block&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)})</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">featureExtractor</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

<span class="n">tdnn</span> <span class="o">=</span> <span class="n">TimeDelayNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tdnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="neuralnets.TimeDelayNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>features</em>, <em>labels</em>, <em>validation_split</em>, <em>batch_size=10</em>, <em>epochs=20</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TimeDelayNN.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TimeDelayNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the neural net on the data provided.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> – Numpy array of training data.</li>
<li><strong>labels</strong> – Numpy array of target (label) data.</li>
<li><strong>validation_split</strong> – Float between 0 and 1. Percentage of training data to use for validation</li>
<li><strong>batch_size</strong> – </li>
<li><strong>epochs</strong> – Max number of times to train on input data.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="neuralnets.TimeDelayNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TimeDelayNN.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TimeDelayNN.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuralnets.TransferLearningNN">
<em class="property">class </em><code class="descclassname">neuralnets.</code><code class="descname">TransferLearningNN</code><span class="sig-paren">(</span><em>model_name</em>, <em>target_labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TransferLearningNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TransferLearningNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer Learning Convolutional Neural Network initialized with pretrained weights.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model_name</strong> – name of pretrained model to use for initial weights. Options: [‘Xception’, ‘VGG16’, ‘VGG19’, ‘ResNet50’, ‘InceptionV3’, ‘InceptionResNetV2’]</li>
<li><strong>target_labels</strong> – list of target emotion labels</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">csv_file_path</span> <span class="o">=</span> <span class="s1">&#39;&lt;local csv file path&gt;&#39;</span>
<span class="n">target_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>

<span class="n">imageProcessor</span> <span class="o">=</span> <span class="n">ImageProcessor</span><span class="p">(</span><span class="n">from_csv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">target_labels</span><span class="o">=</span><span class="n">target_labels</span><span class="p">,</span> <span class="n">datapath</span><span class="o">=</span><span class="n">csv_file_path</span><span class="p">,</span> <span class="n">target_dimensions</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span> <span class="n">raw_dimensions</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">),</span> <span class="n">csv_label_col</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">csv_image_col</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imageProcessor</span><span class="o">.</span><span class="n">get_training_data</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TransferLearningNN</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;inception_v3&#39;</span><span class="p">,</span> <span class="n">target_labels</span><span class="o">=</span><span class="n">target_labels</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="neuralnets.TransferLearningNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>features</em>, <em>labels</em>, <em>validation_split</em>, <em>epochs=50</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TransferLearningNN.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TransferLearningNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the neural net on the data provided.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> – Numpy array of training data.</li>
<li><strong>labels</strong> – Numpy array of target (label) data.</li>
<li><strong>validation_split</strong> – Float between 0 and 1. Percentage of training data to use for validation</li>
<li><strong>epochs</strong> – Max number of times to train over dataset.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="neuralnets.TransferLearningNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuralnets.html#TransferLearningNN.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuralnets.TransferLearningNN.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="fermodel.html"
                        title="previous chapter">FERModel</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="imageprocessor.html"
                        title="next chapter">ImageProcessor</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="imageprocessor.html" title="ImageProcessor"
             >next</a> |</li>
        <li class="right" >
          <a href="fermodel.html" title="FERModel"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">EmoPy 1.0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, AP.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.5.
    </div>
  </body>
</html>